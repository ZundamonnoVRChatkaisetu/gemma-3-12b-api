# API設定
API_AUTH_REQUIRED=False
API_KEY=your_api_key_here

# モデル選択
USE_OLLAMA=True

# Hugging Face モデル設定 (USE_OLLAMA=Falseの場合に使用)
HF_MODEL_ID=google/gemma-3-12b-it
HF_MODEL_CACHE_DIR=./models
HF_USE_4BIT_QUANTIZATION=True
HF_USE_8BIT_QUANTIZATION=False
HF_USE_FLASH_ATTENTION=True
HF_TOKEN=your_huggingface_token_here

# Ollama設定 (USE_OLLAMA=Trueの場合に使用)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_NAME=gemma3:27b

# 推論設定
MAX_NEW_TOKENS=2048
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.9
DEFAULT_TOP_K=50
DEVICE=cuda

# レート制限
RATE_LIMIT_ENABLED=True
RATE_LIMIT_REQUESTS=50
RATE_LIMIT_WINDOW_SECONDS=3600

# CORSの設定
CORS_ORIGINS=["*"]

# デバッグ
DEBUG=True